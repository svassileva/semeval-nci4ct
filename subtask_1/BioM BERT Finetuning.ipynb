{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6MZRcWUW3C6"
      },
      "source": [
        "## Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zso056gFl-XV"
      },
      "outputs": [],
      "source": [
        "!pip install ray transformers\n",
        "\n",
        "import pandas as pd\n",
        "import random\n",
        "import math\n",
        "import json\n",
        "import os\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "from ray import tune, put, get\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "from functools import partial\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup, ElectraTokenizer, ElectraForSequenceClassification \n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch.optim import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mP8nxK9T5Gu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"sultan/BioM-BERT-PubMed-PMC-Large\""
      ],
      "metadata": {
        "id": "xK-gRWbuleOb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXgrdEAOXF8U"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_train_df = '/path/to/preprocessed/train_df.json'\n",
        "path_to_validation_df = '/path/to/preprocessed/val_df.json'"
      ],
      "metadata": {
        "id": "9UTPex1ykJRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBLFCnsZ90MX"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_json(path_to_train_df)\n",
        "val_df = pd.read_json(path_to_validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLpcTvRrXORn"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Q9OZNqSXSMO"
      },
      "outputs": [],
      "source": [
        "tokenizer = ElectraTokenizer.from_pretrained(model_id)\n",
        "label_dict = {'Entailment': 0, 'Contradiction': 1}\n",
        "MAX_LEN = 512\n",
        "\n",
        "# creates a TensorDataset from a given examples dataframe. \n",
        "def get_dataset(df):\n",
        "  input_token_ids = []\n",
        "  mask_ids = []\n",
        "  segment_ids = []\n",
        "  labels = []\n",
        "\n",
        "  premise_list = df['Premise'].to_list() # this is a list of lists of strings\n",
        "  hypothesis_list = df['Statement'].to_list()\n",
        "  label_list = df['Label'].to_list()\n",
        "  \n",
        "  for (premise, hypothesis, label) in zip(premise_list, hypothesis_list, label_list):\n",
        "    tokenization_output = tokenizer.encode_plus(text=hypothesis,\n",
        "                                                text_pair=' '.join(premise),\n",
        "                                                add_special_tokens=True,\n",
        "                                                truncation=True,\n",
        "                                                max_length=MAX_LEN, \n",
        "                                                return_tensors=\"pt\",\n",
        "                                                return_token_type_ids=True,\n",
        "                                                return_attention_mask=True)\n",
        "    \n",
        "          \n",
        "    out_input_ids = tokenization_output['input_ids'][0]\n",
        "    out_mask_ids = tokenization_output['attention_mask'][0]\n",
        "    out_segment_ids = tokenization_output['token_type_ids'][0]\n",
        "\n",
        "    input_token_ids.append(out_input_ids)\n",
        "    mask_ids.append(out_mask_ids)\n",
        "    segment_ids.append(out_segment_ids)\n",
        "    labels.append(label_dict[label])\n",
        "  \n",
        "  input_token_ids = pad_sequence(input_token_ids, batch_first=True)\n",
        "  mask_ids = pad_sequence(mask_ids, batch_first=True)\n",
        "  segment_ids = pad_sequence(segment_ids, batch_first=True)\n",
        "  labels = torch.tensor(labels)\n",
        "\n",
        "  return TensorDataset(input_token_ids, mask_ids, segment_ids, labels)\n",
        "\n",
        "# creates train and validation dataloaders\n",
        "def get_dataloaders(batch_size):  \n",
        "  train_data = get_dataset(train_df)\n",
        "  train_sampler = RandomSampler(train_data)\n",
        "  train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "  validation_data = get_dataset(val_df)\n",
        "  validation_sampler = SequentialSampler(validation_data)\n",
        "  validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
        "\n",
        "  return train_dataloader, validation_dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95e7MI6yjV-4"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8o-H1xTTjZh1"
      },
      "outputs": [],
      "source": [
        "bertModel = ElectraForSequenceClassification.from_pretrained(model_id, num_labels=2)\n",
        "bertModel.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuhlqSR0kcUk"
      },
      "outputs": [],
      "source": [
        "# Number of training epochs\n",
        "epochs = 3\n",
        "\n",
        "def get_scheduler_and_optimizer(model, learning_rate, batches, adam_epsilon = 1e-8, warmup_steps_ratio=0):\n",
        "  optimizer = AdamW(model.parameters(),\n",
        "                    lr = learning_rate,\n",
        "                    eps = adam_epsilon)\n",
        "  \n",
        "  total_steps = epochs * batches\n",
        "\n",
        "  return get_linear_schedule_with_warmup(optimizer, \n",
        "                                         num_warmup_steps = math.floor(total_steps * warmup_steps_ratio),\n",
        "                                         num_training_steps = total_steps), optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DFa7GeF3o57r"
      },
      "outputs": [],
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlpuYQoklcdV"
      },
      "outputs": [],
      "source": [
        "# Set the seed value to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "def fine_tune(config, model, checkpoint_dir=None):\n",
        "  evaluated_model_ref = get(model)\n",
        "\n",
        "  train_dataloader, validation_dataloader = get_dataloaders(config[\"batch_size\"])\n",
        "  scheduler, optimizer = get_scheduler_and_optimizer(evaluated_model_ref, config[\"learning_rate\"], len(train_dataloader) * epochs, config[\"adam_epsilon\"], config[\"warmup_steps_percentage\"])\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  if checkpoint_dir:\n",
        "    model_state, optimizer_state = torch.load(os.path.join(checkpoint_dir, \"checkpoint\"))\n",
        "    evaluated_model_ref.load_state_dict(model_state)\n",
        "    optimizer.load_state_dict(optimizer_state)\n",
        "\n",
        "  for epoch_i in range(0, epochs):\n",
        "      evaluated_model_ref.train()\n",
        "\n",
        "      for step, (pair_token_ids, mask_ids, seg_ids, y) in enumerate(train_dataloader):\n",
        "\n",
        "          evaluated_model_ref.zero_grad()   \n",
        "\n",
        "          pair_token_ids = pair_token_ids.to(device)\n",
        "          mask_ids = mask_ids.to(device)\n",
        "          seg_ids = seg_ids.to(device)\n",
        "          labels = y.to(device)     \n",
        "\n",
        "          loss, prediction = evaluated_model_ref(pair_token_ids, \n",
        "                                  token_type_ids=seg_ids, \n",
        "                                  attention_mask=mask_ids, \n",
        "                                  labels=labels).values()\n",
        "\n",
        "          loss.backward()\n",
        "\n",
        "          torch.nn.utils.clip_grad_norm_(evaluated_model_ref.parameters(), 1.0)\n",
        "\n",
        "          optimizer.step()\n",
        "\n",
        "          scheduler.step()\n",
        "    \n",
        "      evaluated_model_ref.eval()\n",
        "\n",
        "      # Tracking variables \n",
        "      eval_loss, eval_accuracy = 0, 0\n",
        "      nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "      for (pair_token_ids, mask_ids, seg_ids, labels) in validation_dataloader:\n",
        "\n",
        "          pair_token_ids = pair_token_ids.to(device)\n",
        "          mask_ids = mask_ids.to(device)\n",
        "          seg_ids = seg_ids.to(device)\n",
        "          labels = labels.to(device)\n",
        "\n",
        "          with torch.no_grad():        \n",
        "\n",
        "              outputs = evaluated_model_ref(pair_token_ids, \n",
        "                              token_type_ids=seg_ids, \n",
        "                              attention_mask=mask_ids)\n",
        "          \n",
        "          logits = outputs[0]\n",
        "\n",
        "          logits = logits.detach().cpu().numpy()\n",
        "          label_ids = labels.to('cpu').numpy()\n",
        "\n",
        "          tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "          tmp_eval_loss = criterion(torch.tensor(logits), torch.tensor(label_ids))\n",
        "          \n",
        "          eval_accuracy += tmp_eval_accuracy\n",
        "          eval_loss += tmp_eval_loss\n",
        "\n",
        "          nb_eval_steps += 1\n",
        "\n",
        "      with tune.checkpoint_dir(epoch_i) as checkpoint_dir:\n",
        "        path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "        torch.save((evaluated_model_ref.state_dict(), optimizer.state_dict()), path)\n",
        "            \n",
        "      tune.report(loss=(eval_loss/nb_eval_steps), accuracy=eval_accuracy/nb_eval_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0Q6RRz8ESzo"
      },
      "outputs": [],
      "source": [
        "# Driver cell\n",
        "\n",
        "# hyperparameter tuning configuration. Add values to the corresponding tune.choice list to include them in the search. \n",
        "config = {\n",
        "    \"learning_rate\": tune.choice([2e-5]),\n",
        "    \"batch_size\": tune.choice([16]),\n",
        "    \"adam_epsilon\": tune.choice([1e-8]),\n",
        "    \"warmup_steps_percentage\": tune.choice([0.02])\n",
        "    }\n",
        "\n",
        "scheduler = ASHAScheduler(\n",
        "    metric=\"accuracy\",\n",
        "    mode=\"max\",\n",
        "    max_t=epochs,\n",
        "    grace_period=2,\n",
        "    reduction_factor=2)\n",
        "\n",
        "reporter = CLIReporter(\n",
        "    metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
        "\n",
        "# Create a ref to the model to pass to the fine_tune function.\n",
        "# The model is ~1.3 GiB. If it is directly referenced in our fine_tune method, Ray will throw a 'worker function too big > 95MiB' error.\n",
        "modelRef = put(bertModel)\n",
        "\n",
        "result = tune.run(\n",
        "    partial(fine_tune, model=modelRef),\n",
        "    resources_per_trial={\"gpu\": 1},\n",
        "    config=config,\n",
        "    num_samples=3,\n",
        "    scheduler=scheduler,\n",
        "    progress_reporter=reporter)\n",
        "\n",
        "best_trial = result.get_best_trial(\"accuracy\", \"max\", \"all\")\n",
        "print(\"Best trial config: {}\".format(best_trial.config))\n",
        "print(\"Best trial final validation loss: {}\".format(best_trial.last_result[\"loss\"]))\n",
        "print(\"Best trial final validation accuracy: {}\".format(best_trial.last_result[\"accuracy\"]))\n",
        "result.get_best_checkpoint(trial, \"accuracy\", \"max\", \"all\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}